function [data,basis,B,source] = generate_artificial_data(parm)
% generate_artificial_data - generate artificial signals used in simulations.
%
% [data,basis,B,source] = generate_artificial_data(parm)
%
% Generate artificial data used in simulation. The observation(data) 
% of each time point is a vectorized square image [imageSize x imageSize]
% generated by the following procedures:
%   1. There is a set of "Nbasis" spatial bases ("basis") common across subjects and runs.
%      Each spatial basis has sparsity determined by "basisSparsity".
%   2. For each time point, averagely "basisNactive" spatial bases are activated simultaneously,
%      and observed as a summation of them.
%   3. Each subject and run has a subject-run-specific spatial transform "B"
%      specified by blurring (Gaussian: size-blk.blursize, std.-blk.blurstd) and 
%      spatial 2D-shift (blk.shift).
%   4. Noises(std: "noiseStd") are added.
%
% --- Input ------------------------------------------------------
% parm [struct]
%   .imageSize      : image size (default: 4)
%   .Nbasis         : number of spatial bases (default: imageSize^2*2)
%   .basisSparsity  : sparsity of elements of the spatial basis (default: 0.2)
%   .basisNactive   : average number of spatial bases activated
%                     on each time point (default: 4)
%   .noiseStd       : standard deviation of noises (default: 0)
%   .blk [structure array; 1 x (Nsubject x Nrun)]
%       .subject    : subject name
%       .run        : run name
%       .Ndata      : number of data of the run
%       .blursize   : size of gaussian blur during the run
%       .blurstd    : std. of gaussian blur during the run
%       .shift      : spatial shift of observation during the run [x, y]
%
% --- Output -----------------------------------------------------
% data [struct]
%   .x      : artificial data temporaly concatenated across
%             subjects and runs [imageSize^2 x Ntime]
%   .s      : subject label of each time point [1 x Ntime]
%   .r      : run label of each time point [1 x Ntime]
% basis     : spatial bases common across subjects and runs [imageSize^2 x Nbasis]
% B [structure array; 1 x (Nsubject x Nrun)]
%   .mat    : subject-run-specific spatial transform [imageSize^2 x imageSize^2]
%   .s      : subject name
%   .r      : run name
% source    : activities on the spatial bases.
%
% Note: This function depends on Image Processing Toolbox.
%
% Version 1.0, July 1 2015
% Author: Hiroshi Morioka
% License: Apache License, Version 2.0
%

if isfield(parm,'imageSize'), imageSize = parm.imageSize; else imageSize = 4; end
if isfield(parm,'Nbasis'), Nbasis = parm.Nbasis; else Nbasis = imageSize^2*2; end
if isfield(parm,'basisSparsity'), basisSparsity = parm.basisSparsity; else basisSparsity = 0.2; end
if isfield(parm,'basisNactive'), basisNactive = parm.basisNactive; else basisNactive = 4; end
if isfield(parm,'noiseStd'), noiseStd = parm.noiseStd; else noiseStd = 0; end
if isfield(parm,'blk'), blk = parm.blk; else blk = []; end


% Make artificial data -----------------------------------------
% -------------------------------------------------------

% Spatial basis (fixed)
if basisSparsity < 0, basisSparsity = 0; end
if basisSparsity > 1, basisSparsity = 1; end
basis = zeros(imageSize.^2, Nbasis);
while min(max(abs(basis),[],1))==0 || size(unique(basis','rows'),1) < Nbasis
    basis = double(rand(imageSize.^2, Nbasis) > (1-basisSparsity));
end
basis = mexNormalize(basis);


B = [];
B2D = [];
data = struct('x',[],'s',[],'r',[],'t',[]);
for rn = 1:length(blk)
    subject = blk(rn).subject;
    run = blk(rn).run;
    Ndata = blk(rn).Ndata;
    
    % Spatial trnasform (B) ----------------------------
    % --------------------------------------------------
    blur2D = zeros(blk(rn).blursize+2); 
    % blur
    blur2D(2:end-1,2:end-1) = fspecial('gaussian', blk(rn).blursize, blk(rn).blurstd);  
    % shift
    tform = maketform('affine',[1 0 0; 0 1 0; blk(rn).shift(1) blk(rn).shift(2) 1]);
    blur2D = imtransform(blur2D,tform,'XData',[1 size(blur2D,2)],'YData',[1 size(blur2D,1)]);
    B2D(rn).mat = blur2D;

    % calculate blurred observation for each pixel ---------------
    Brn = [];
    for xn = 1:imageSize
        for yn = 1:imageSize
            pixelData = zeros(imageSize);
            pixelData(xn,yn) = 1;
            Brn(xn,yn,:,:) = imfilter(pixelData,blur2D); % apply 2D-blur
        end
    end
    Brn = reshape(Brn,[size(Brn,1)*size(Brn,2), size(Brn,3)*size(Brn,4)])';
    B(rn).mat = Brn;
    B(rn).s = subject;
    B(rn).r = run;
    
    % activity on basis --------------------------------
    % --------------------------------------------------
    Nactive = poissrnd(basisNactive-1,Ndata,1)+1;
    Nactive(Nactive > Nbasis) = Nbasis;

    source = zeros(Nbasis,Ndata);
    [~,randIdx] = sort(rand(Nbasis,Ndata),1,'descend');
    for dn = 1:Ndata
        source(randIdx(1:Nactive(dn),dn),dn) = 1;
    end
    
    % Blurred observation (data) -----------------------
    % --------------------------------------------------
    x = Brn * basis * source;
    % add noise
    x = x + noiseStd*randn(size(x));
 
    
    % Concatenate temporaly ----------------------------
    % --------------------------------------------------
    data.x = [data.x, x];
    data.s = [data.s, subject*ones(1,Ndata)];
    data.r = [data.r, run*ones(1,Ndata)];
    
end

% Plot 2D blurring of each subject and run
showmatgrid(reshape([B2D.mat],[size(B2D(1).mat,1),size(B2D(1).mat,2),length(B2D)]),...
    struct('crange','common','title','blurring on 2D'))


